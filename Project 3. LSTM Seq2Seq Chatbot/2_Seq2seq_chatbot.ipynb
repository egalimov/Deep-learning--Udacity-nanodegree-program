{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w4JUQ0UAGiu0",
    "outputId": "790aff14-c7b9-4174-9c0b-a23f7e7281cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IbNbzHOyGixs"
   },
   "outputs": [],
   "source": [
    "# enter the directory \n",
    "%cd /content/gdrive/MyDrive/1_Udacity/3_RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sNVOpyXw7Oxf"
   },
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import gensim\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import torch\n",
    "from nltk.corpus import brown\n",
    "from torchtext.datasets import SQuAD1\n",
    "import string\n",
    "import pickle \n",
    "import torch.nn as nn\n",
    "import random \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FnQwPkAR-zRX",
    "outputId": "8fcd2717-9eb0-4006-8f7d-81c7d7f2cb6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting livelossplot\n",
      "  Downloading livelossplot-0.5.5-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: bokeh in /usr/local/lib/python3.8/dist-packages (from livelossplot) (2.4.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from livelossplot) (3.5.3)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.8/dist-packages (from bokeh->livelossplot) (8.4.0)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.8/dist-packages (from bokeh->livelossplot) (3.1.2)\n",
      "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.8/dist-packages (from bokeh->livelossplot) (23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.8/dist-packages (from bokeh->livelossplot) (4.5.0)\n",
      "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.8/dist-packages (from bokeh->livelossplot) (6.2)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.8/dist-packages (from bokeh->livelossplot) (6.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.8/dist-packages (from bokeh->livelossplot) (1.22.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->livelossplot) (4.38.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->livelossplot) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->livelossplot) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->livelossplot) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->livelossplot) (2.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib->livelossplot) (1.15.0)\n",
      "Installing collected packages: livelossplot\n",
      "Successfully installed livelossplot-0.5.5\n"
     ]
    }
   ],
   "source": [
    "# Installing and loading additional packages\n",
    "# Restart after run\n",
    "!pip install livelossplot\n",
    "from livelossplot import PlotLosses\n",
    "from livelossplot.outputs import MatplotlibPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3VNG5z-px55v"
   },
   "outputs": [],
   "source": [
    "# loading stemmer and creating tokenizer\n",
    "stemmer = nltk.stem.snowball.SnowballStemmer('english')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UikmIu7Rx7Oa"
   },
   "outputs": [],
   "source": [
    "# Load Squad1 training data data obtailed using 'Data_table_prep.ipynb' - that notebook was run on local computer\n",
    "train_data = pd.read_csv('train_data_sq1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mg8vMFT7x6H3"
   },
   "outputs": [],
   "source": [
    "# create vocabulary objects\n",
    "PAD_token = 0  # Used for padding short sentences\n",
    "SOS_token = 1  # Start-of-sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.words2index = {}\n",
    "        self.word_number = 3\n",
    "        self.index2word = {PAD_token: \"<PAD>\", SOS_token: \"<SOS>\", EOS_token: \"<EOS>\"}\n",
    "        self.word2count = {}\n",
    "        \n",
    "    def cleanText(self, text):\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        text = tokenizer.tokenize(text)\n",
    "        return text\n",
    "\n",
    "    def indexWord(self, word):\n",
    "        word = word.lower()\n",
    "        if word not in self.words2index:\n",
    "            self.words2index[word] = self.word_number\n",
    "            self.index2word[self.word_number] = word\n",
    "            self.word2count[word] = 1\n",
    "            self.word_number +=1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    def trim(self, min_count_allowed):\n",
    "\n",
    "        td = self.word2count\n",
    "        trimmed_words = pd.DataFrame([td]).T\n",
    "        trimmed_words.rename(columns={ trimmed_words.columns[0]: \"counts\" }, inplace = True)\n",
    "        trimmed_words['words'] = trimmed_words.index\n",
    "        trimmed_words = trimmed_words[trimmed_words[\"counts\"]>=min_count_allowed]\n",
    "\n",
    "        trimmed_words = trimmed_words['words'].tolist()\n",
    "        # Reinitialize dictionaries\n",
    "        self.words2index = {}\n",
    "        self.word_number = 3\n",
    "        self.index2word = {PAD_token: \"<PAD>\", SOS_token: \"<SOS>\", EOS_token: \"<EOS>\"}\n",
    "        self.word2count = {}\n",
    "\n",
    "        for word in trimmed_words:\n",
    "            self.indexWord(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJeY85Kgx6KP"
   },
   "outputs": [],
   "source": [
    "# remove missing data\n",
    "train_data_qa = train_data[train_data['Answer'].notna()]\n",
    "train_data_qa = train_data_qa.reset_index(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6O8A8hHx6Mq"
   },
   "outputs": [],
   "source": [
    "# further data preprocessing\n",
    "\n",
    "# function from https://github.com/iJoud/Seq2Seq-Chatbot/blob/main/src/Data.py\n",
    "def prepare_text(sentence):\n",
    "    # clean text and tokenize it \n",
    "    sentence = ''.join([s.lower() for s in sentence if s not in string.punctuation])\n",
    "    sentence = ' '.join(stemmer.stem(w) for w in sentence.split())\n",
    "    tokens = nltk.tokenize.RegexpTokenizer(r'\\w+').tokenize(sentence)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "train_data_qa['q_tokens'] = ''\n",
    "train_data_qa['q_tokens'].astype(object)\n",
    "train_data_qa['a_tokens'] = ''\n",
    "train_data_qa['a_tokens'].astype(object)\n",
    "\n",
    "\n",
    "for i in range(0, train_data_qa.shape[0]):\n",
    "    #print(i)\n",
    "    # i=0    \n",
    "    train_data_qa.at[i,'q_tokens'] = prepare_text(train_data_qa.loc[i,'Question'])\n",
    "    train_data_qa.at[i,'a_tokens'] = prepare_text(train_data_qa.loc[i,'Answer'])\n",
    "\n",
    "\n",
    "\n",
    "# creating disctionaries\n",
    "miss = 0\n",
    "SRC = Vocab('squad_q')\n",
    "for i in range(0, train_data_qa.shape[0]): \n",
    " \n",
    "    if type(train_data_qa.loc[i, 'Question']) == str:\n",
    "        for j in train_data_qa.loc[i, 'q_tokens']:\n",
    "            SRC.indexWord(j)\n",
    "    else: \n",
    "        miss+=1\n",
    "        next\n",
    "\n",
    "miss = 0\n",
    "TRG = Vocab('squad_a')\n",
    "for i in range(0, train_data_qa.shape[0]):\n",
    "    if type(train_data_qa.loc[i, 'Answer']) == str:\n",
    "        for j in train_data_qa.loc[i, 'a_tokens']:\n",
    "            TRG.indexWord(j)\n",
    "    else: \n",
    "        miss+=1\n",
    "        next\n",
    "\n",
    "# trimming disctionaries\n",
    "SRC.trim(2)\n",
    "TRG.trim(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TxPhldnJx6Ov"
   },
   "outputs": [],
   "source": [
    "# remove the  Q&A pairs which contain words trimmed from any of 2 vocabularies\n",
    "train_data_qa['keep'] = True\n",
    "# Remove Q&A if they contain rare words\n",
    "for i in range(0, train_data_qa.shape[0]): \n",
    "    # i = 0\n",
    "    #print(i)\n",
    "    list_temp = train_data_qa.loc[i, 'q_tokens'] + train_data_qa.loc[i, 'a_tokens']\n",
    "    for j in list_temp:\n",
    "        j = j.lower()\n",
    "        if ( (j not in SRC.words2index) | (j not in TRG.words2index) ):\n",
    "            train_data_qa.loc[i,'keep'] = False\n",
    "\n",
    "train_data_qa_trim = train_data_qa[train_data_qa['keep']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eWhKMw-2tZ-f",
    "outputId": "8db72df2-1776-430f-9734-a5ba97adce76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15670\n",
      "15504\n"
     ]
    }
   ],
   "source": [
    "print( SRC.word_number )\n",
    "print( TRG.word_number )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJOfbN2b0jbp"
   },
   "outputs": [],
   "source": [
    "# function to convert words to indexes\n",
    "def conv2index(input_list, vocab):\n",
    "    indices = [vocab.words2index[word] for word in input_list]\n",
    "    indices = [1] + indices + [2] \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h_MvQpH30jeB"
   },
   "outputs": [],
   "source": [
    "# removing NA\n",
    "train_data_qa_trim = train_data_qa_trim[train_data_qa_trim['Answer'].notna()]\n",
    "\n",
    "# adding columns with lists of indexes\n",
    "source_data = []\n",
    "target_data = []\n",
    "for i in range(0, train_data_qa_trim.shape[0]):\n",
    "    #print(i)\n",
    "    source_data.append(  conv2index(train_data_qa_trim.iloc[i,3], SRC)  )\n",
    "    target_data.append(  conv2index(train_data_qa_trim.iloc[i,4], TRG)  )\n",
    "    \n",
    "train_data_qa_trim['Q_indexes'] = source_data  \n",
    "train_data_qa_trim['A_indexes'] = target_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "LBnCK4Wa0jgj",
    "outputId": "4e997733-ac4b-47f5-aba8-edb4af56b86e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f42a7da6-24c7-48cf-a6f7-bebd17a90805\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>q_tokens</th>\n",
       "      <th>a_tokens</th>\n",
       "      <th>keep</th>\n",
       "      <th>Q_indexes</th>\n",
       "      <th>A_indexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>[what, is, in, front, of, the, notr, dame, mai...</td>\n",
       "      <td>[a, copper, statu, of, christ]</td>\n",
       "      <td>True</td>\n",
       "      <td>[1, 15, 16, 11, 17, 18, 6, 19, 20, 21, 22, 2]</td>\n",
       "      <td>[1, 4, 5, 6, 7, 8, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>[the, basilica, of, the, sacr, heart, at, notr...</td>\n",
       "      <td>[the, main, build]</td>\n",
       "      <td>True</td>\n",
       "      <td>[1, 6, 23, 18, 6, 24, 25, 26, 19, 20, 16, 27, ...</td>\n",
       "      <td>[1, 9, 10, 11, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>[what, sit, on, top, of, the, main, build, at,...</td>\n",
       "      <td>[a, golden, statu, of, the, virgin, mari]</td>\n",
       "      <td>True</td>\n",
       "      <td>[1, 15, 31, 32, 33, 18, 6, 21, 22, 26, 19, 20, 2]</td>\n",
       "      <td>[1, 4, 17, 6, 7, 9, 18, 19, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>When did the Scholastic Magazine of Notre dame...</td>\n",
       "      <td>September 1876</td>\n",
       "      <td>[when, did, the, scholast, magazin, of, notr, ...</td>\n",
       "      <td>[septemb, 1876]</td>\n",
       "      <td>True</td>\n",
       "      <td>[1, 34, 5, 6, 35, 36, 18, 19, 20, 37, 38, 2]</td>\n",
       "      <td>[1, 20, 21, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>What is the daily student paper at Notre Dame ...</td>\n",
       "      <td>The Observer</td>\n",
       "      <td>[what, is, the, daili, student, paper, at, not...</td>\n",
       "      <td>[the, observ]</td>\n",
       "      <td>True</td>\n",
       "      <td>[1, 15, 16, 6, 41, 42, 43, 26, 19, 20, 44, 2]</td>\n",
       "      <td>[1, 9, 23, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f42a7da6-24c7-48cf-a6f7-bebd17a90805')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f42a7da6-24c7-48cf-a6f7-bebd17a90805 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f42a7da6-24c7-48cf-a6f7-bebd17a90805');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   index                                           Question  \\\n",
       "1      1  What is in front of the Notre Dame Main Building?   \n",
       "2      2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "4      4  What sits on top of the Main Building at Notre...   \n",
       "5      5  When did the Scholastic Magazine of Notre dame...   \n",
       "7      7  What is the daily student paper at Notre Dame ...   \n",
       "\n",
       "                               Answer  \\\n",
       "1           a copper statue of Christ   \n",
       "2                   the Main Building   \n",
       "4  a golden statue of the Virgin Mary   \n",
       "5                      September 1876   \n",
       "7                        The Observer   \n",
       "\n",
       "                                            q_tokens  \\\n",
       "1  [what, is, in, front, of, the, notr, dame, mai...   \n",
       "2  [the, basilica, of, the, sacr, heart, at, notr...   \n",
       "4  [what, sit, on, top, of, the, main, build, at,...   \n",
       "5  [when, did, the, scholast, magazin, of, notr, ...   \n",
       "7  [what, is, the, daili, student, paper, at, not...   \n",
       "\n",
       "                                    a_tokens  keep  \\\n",
       "1             [a, copper, statu, of, christ]  True   \n",
       "2                         [the, main, build]  True   \n",
       "4  [a, golden, statu, of, the, virgin, mari]  True   \n",
       "5                            [septemb, 1876]  True   \n",
       "7                              [the, observ]  True   \n",
       "\n",
       "                                           Q_indexes  \\\n",
       "1      [1, 15, 16, 11, 17, 18, 6, 19, 20, 21, 22, 2]   \n",
       "2  [1, 6, 23, 18, 6, 24, 25, 26, 19, 20, 16, 27, ...   \n",
       "4  [1, 15, 31, 32, 33, 18, 6, 21, 22, 26, 19, 20, 2]   \n",
       "5       [1, 34, 5, 6, 35, 36, 18, 19, 20, 37, 38, 2]   \n",
       "7      [1, 15, 16, 6, 41, 42, 43, 26, 19, 20, 44, 2]   \n",
       "\n",
       "                        A_indexes  \n",
       "1           [1, 4, 5, 6, 7, 8, 2]  \n",
       "2               [1, 9, 10, 11, 2]  \n",
       "4  [1, 4, 17, 6, 7, 9, 18, 19, 2]  \n",
       "5                  [1, 20, 21, 2]  \n",
       "7                   [1, 9, 23, 2]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_qa_trim.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GbU0hfLQ20zn",
    "outputId": "f7a43e32-41b0-4fbd-c30c-95e6e0b9771d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 15 16 11 17 18  6 19 20 21 22  2]\n",
      "[1 4 5 6 7 8 2]\n"
     ]
    }
   ],
   "source": [
    "# defining the device\n",
    "device = 'cuda'\n",
    "#device = 'cpu'\n",
    "\n",
    "# creating tensors using the defined device\n",
    "source_data = []\n",
    "target_data = []\n",
    "for i in range(0,train_data_qa_trim.shape[0]):\n",
    "    source_data.append(torch.Tensor(train_data_qa_trim.iloc[i,6]).long().to(device))\n",
    "    target_data.append(torch.Tensor(train_data_qa_trim.iloc[i,7]).long().to(device))\n",
    "\n",
    "print( source_data[0].cpu().numpy() ) \n",
    "print( target_data[0].cpu().numpy() ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9DBOcNz28u_",
    "outputId": "60d7b27a-d54d-4ec0-8e67-d7d17613342e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# limiting the data to the first 6000 Q&A pairs to accelerate the training\n",
    "source_data = source_data[0:6000]\n",
    "target_data = target_data[0:6000]\n",
    "len(source_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w4p16HcqucBQ",
    "outputId": "668a60f1-43da-46a1-94e6-a72083c578db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  9, 10, 11,  2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the data\n",
    "target_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S2VnwLW5N-xy",
    "outputId": "1e91b596-6a3b-4625-c3f4-1fbeae30c6d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 15 16 11 17 18  6 19 20 21 22  2]\n",
      "[1 4 5 6 7 8 2]\n"
     ]
    }
   ],
   "source": [
    "#pickle.dump( source_data, open( \"source_data230305_6000.p\", \"wb\" ) ) \n",
    "#pickle.dump( target_data, open( \"target_data230305_6000.p\", \"wb\" ) ) \n",
    "source_data = pickle.load( open( \"source_data230305_6000.p\", \"rb\" ) ) \n",
    "target_data = pickle.load( open( \"target_data230305_6000.p\", \"rb\" ) ) \n",
    "print( source_data[0].cpu().numpy() ) \n",
    "print( target_data[0].cpu().numpy() ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GVMWUhiUOlGp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_PAcP-I5TSD"
   },
   "source": [
    "# Create Seq2Seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vW-rA624-zRd"
   },
   "outputs": [],
   "source": [
    "# Defining the Encoder, Decoder and Seq2Seq\n",
    "\n",
    "# based on the model from  https://github.com/iJoud/Seq2Seq-Chatbot/blob/main/src/Models.py\n",
    "class Encoder(nn.Module):\n",
    "  \n",
    "    def __init__(self, input_size, emb_size, hidden_size, n_layers, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.emb_size = emb_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(self.input_size, self.emb_size)\n",
    "        # self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n",
    "        self.rnn = nn.LSTM(emb_size, hidden_size, n_layers, dropout = dropout)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, hidden, cell_state):\n",
    "        \n",
    "        x = self.dropout( self.embedding(x).view(1, 1, -1) )\n",
    "        x, (hidden, cell_state) = self.rnn(x, (hidden, cell_state))\n",
    "        \n",
    "        return x, hidden, cell_state\n",
    "        \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, output_size, emb_size, hidden_size, n_layers, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.emb_size = emb_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.emb_size)\n",
    "\n",
    "        self.rnn = nn.LSTM(emb_size, hidden_size, n_layers, dropout = dropout)\n",
    "        # self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x, hidden, cell_state):\n",
    "        \n",
    "        x = self.dropout( self.embedding(x).view(1, 1, -1) )\n",
    "        x, (hidden, cell_state) = self.rnn(x, (hidden, cell_state))\n",
    "        x = self.softmax(self.fc(x[0]))\n",
    "        \n",
    "        return x, hidden, cell_state\n",
    "    \n",
    "     \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, emb_size, n_layers, dropout):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.emb_size = emb_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.encoder = Encoder(self.input_size, self.emb_size, self.hidden_size, self.n_layers, dropout)\n",
    "        self.decoder = Decoder(self.output_size, self.emb_size, self.hidden_size, self.n_layers, dropout)\n",
    "        \n",
    "    def forward(self, src, trg, teacher_force, training ):\n",
    "        \n",
    "        output = []\n",
    "       \n",
    "        encoder_hidden = torch.ones([n_layers, 1, hidden_size]).to(device) \n",
    "        cell_state = torch.ones([n_layers, 1, hidden_size]).to(device)  \n",
    "\n",
    "        for i in range(src.size()[0]):\n",
    "            encoder_output, encoder_hidden, cell_state = self.encoder(src[i], encoder_hidden, cell_state)\n",
    "\n",
    "        decoder_input = torch.Tensor([[1]]).long().to(device) \n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        for i in range(trg.size()[0]): \n",
    "            decoder_output, decoder_hidden, cell_state = self.decoder(decoder_input, decoder_hidden, cell_state)\n",
    "            output.append(torch.squeeze(decoder_output) )     \n",
    "            if training:\n",
    "                if random.random() < teacher_force:\n",
    "                    decoder_input = trg[i]\n",
    "                else:\n",
    "                    decoder_input = decoder_output.argmax(1) \n",
    "            else:\n",
    "                decoder_input = torch.argmax(decoder_output,1).view(1, 1) \n",
    "                        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tiP6qX8A-zRd"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1TxciRdZ6N4"
   },
   "outputs": [],
   "source": [
    "# Defining the training loop\n",
    "\n",
    "# based on https://github.com/iJoud/Seq2Seq-Chatbot/blob/main/src/Train.py\n",
    "def train_one_epoch(model, source_data, target_data, batch_size, optimizer, criterion, eploch_random_state):\n",
    "    \n",
    "    model.to(device)\n",
    "    total_training_loss = 0\n",
    "    total_valid_loss = 0\n",
    "    batch_loss = 0\n",
    " \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(source_data, target_data, test_size=0.166, random_state=eploch_random_state)\n",
    "\n",
    "\n",
    "    # train loop\n",
    "    model.train()\n",
    "    for i in range(0, len(X_train)):\n",
    "        src = X_train[i]\n",
    "        trg = y_train[i]\n",
    "        \n",
    "        teacher_force = 0\n",
    "        training = True\n",
    "        out = model(src, trg, teacher_force, training)\n",
    "\n",
    "        word_loss = 0\n",
    "        for (s_char, t_char) in zip(out, trg): \n",
    "            word_loss += criterion(s_char, t_char)\n",
    "\n",
    "        batch_loss += word_loss\n",
    "        total_training_loss += (word_loss / trg.size(0))\n",
    "\n",
    "        if i % batch_size == 0 or i == (len(X_train)-1):\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss = 0\n",
    "\n",
    "    training_loss_average = total_training_loss / len(X_train)\n",
    "    # validation loop\n",
    "    model.eval()\n",
    "    for i in range(0, len(X_test)):\n",
    "        src = X_test[i]\n",
    "        trg = y_test[i]\n",
    "\n",
    "        teacher_force = 0\n",
    "        training = False\n",
    "        output = model(src, trg, teacher_force, training)\n",
    "\n",
    "        word_loss = 0\n",
    "        for (s_char, t_char) in zip(output, trg): \n",
    "            word_loss += criterion(s_char, t_char)\n",
    "\n",
    "        total_valid_loss += (word_loss / trg.size(0))\n",
    "\n",
    "    validation_loss_average = total_valid_loss / len(X_test)\n",
    "\n",
    "    return training_loss_average, validation_loss_average\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l6LVHTHh5-Ph"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "\n",
    "# Useful functions for monitoring the performance\n",
    "\n",
    "# from Udacity solution for Improving performance (CNN in depth)\n",
    "def after_subplot(ax: plt.Axes, group_name: str, x_label: str):\n",
    "    \"\"\"Add title xlabel and legend to single chart\"\"\"\n",
    "    ax.set_title(group_name)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.legend(loc=\"center right\")\n",
    "\n",
    "    if group_name.lower() == \"loss\":\n",
    "        ax.set_ylim([0, 10])\n",
    "\n",
    "# from https://github.com/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620
    },
    "id": "_CYWdG1JziSh",
    "outputId": "9a5582e0-776b-4d2f-96e4-c2698b10a2db"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180 | Time: 1m 2s\n",
      "\tTrain Loss: 0.056 \n"
     ]
    }
   ],
   "source": [
    "# looping over based on optimise function from train.py in Landmark classification project\n",
    "\n",
    "# setting the device\n",
    "device = 'cuda'\n",
    "\n",
    "# setting hyperparameters\n",
    "learning_rate = 0.01\n",
    "\n",
    "input_size = SRC.word_number\n",
    "hidden_size = 128\n",
    "output_size = TRG.word_number\n",
    "\n",
    "emb_size = 128\n",
    "n_layers = 2\n",
    "dropout = 0\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "epochs = 180\n",
    "\n",
    "# initiating the model, optimiser and loss function\n",
    "model = Seq2Seq(SRC.word_number , hidden_size, TRG.word_number, emb_size, n_layers, dropout)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# looping through the eploches\n",
    "best_train_loss = float('inf')\n",
    "\n",
    "logs = {}\n",
    "liveloss = PlotLosses(outputs=[MatplotlibPlot(after_subplot=after_subplot)])\n",
    "epoch=0\n",
    "for epoch_random_state in random.sample(range(100, 1000), epochs):\n",
    "    start_time = time.time()\n",
    "    train_avg_loss, valid_avg_loss = train_one_epoch(model, source_data, target_data, batch_size, optimizer, criterion, epoch_random_state)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if (train_avg_loss < best_train_loss) and (epoch%10==0):\n",
    "        best_train_loss = train_avg_loss\n",
    "        save_name = 'd1_weight'+str(epoch)+'.pt' \n",
    "        torch.save(model.state_dict(), save_name)\n",
    "\n",
    "    logs[\"loss\"] = float(train_avg_loss.detach().cpu().numpy())\n",
    "    logs[\"lr\"] = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    liveloss.update(logs)\n",
    "    liveloss.send()\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_avg_loss:.3f} ')\n",
    "    epoch+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IejbYnbo-zRe"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bn4eP6DyD29A",
    "outputId": "87db87b4-3739-467a-8e63-8b1bdbf73b2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(15670, 128)\n",
       "    (rnn): LSTM(128, 128, num_layers=2)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "    (embedding): Embedding(15504, 128)\n",
       "    (rnn): LSTM(128, 128, num_layers=2)\n",
       "    (fc): Linear(in_features=128, out_features=15504, bias=True)\n",
       "    (softmax): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining the hyperparameters for the trained chatbot \n",
    "device = \"cuda\"\n",
    "hidden_size = 128\n",
    "emb_size = 128\n",
    "n_layers = 2\n",
    "dropout = 0\n",
    "\n",
    "# loading the trained chatbot with weights\n",
    "seq2seq = Seq2Seq(SRC.word_number , hidden_size, TRG.word_number, emb_size, n_layers, dropout)\n",
    "seq2seq.load_state_dict(torch.load('d1_weight170.pt',map_location=device))\n",
    "seq2seq.to(torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1AczEnoJ-zRe"
   },
   "source": [
    "# ex, Question & Answer List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "uBQEc-jQf6-g",
    "outputId": "5347a0ad-ca68-412e-dd57-5106f4fe6d97"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7e76da02-a0d2-409b-bb52-b3cfe1c56b84\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>q_tokens</th>\n",
       "      <th>a_tokens</th>\n",
       "      <th>keep</th>\n",
       "      <th>Q_indexes</th>\n",
       "      <th>A_indexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>[what, is, in, front, of, the, notr, dame, mai...</td>\n",
       "      <td>[a, copper, statu, of, christ]</td>\n",
       "      <td>True</td>\n",
       "      <td>[1, 15, 16, 11, 17, 18, 6, 19, 20, 21, 22, 2]</td>\n",
       "      <td>[1, 4, 5, 6, 7, 8, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>[the, basilica, of, the, sacr, heart, at, notr...</td>\n",
       "      <td>[the, main, build]</td>\n",
       "      <td>True</td>\n",
       "      <td>[1, 6, 23, 18, 6, 24, 25, 26, 19, 20, 16, 27, ...</td>\n",
       "      <td>[1, 9, 10, 11, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>[what, sit, on, top, of, the, main, build, at,...</td>\n",
       "      <td>[a, golden, statu, of, the, virgin, mari]</td>\n",
       "      <td>True</td>\n",
       "      <td>[1, 15, 31, 32, 33, 18, 6, 21, 22, 26, 19, 20, 2]</td>\n",
       "      <td>[1, 4, 17, 6, 7, 9, 18, 19, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e76da02-a0d2-409b-bb52-b3cfe1c56b84')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7e76da02-a0d2-409b-bb52-b3cfe1c56b84 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7e76da02-a0d2-409b-bb52-b3cfe1c56b84');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   index                                           Question  \\\n",
       "1      1  What is in front of the Notre Dame Main Building?   \n",
       "2      2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "4      4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                               Answer  \\\n",
       "1           a copper statue of Christ   \n",
       "2                   the Main Building   \n",
       "4  a golden statue of the Virgin Mary   \n",
       "\n",
       "                                            q_tokens  \\\n",
       "1  [what, is, in, front, of, the, notr, dame, mai...   \n",
       "2  [the, basilica, of, the, sacr, heart, at, notr...   \n",
       "4  [what, sit, on, top, of, the, main, build, at,...   \n",
       "\n",
       "                                    a_tokens  keep  \\\n",
       "1             [a, copper, statu, of, christ]  True   \n",
       "2                         [the, main, build]  True   \n",
       "4  [a, golden, statu, of, the, virgin, mari]  True   \n",
       "\n",
       "                                           Q_indexes  \\\n",
       "1      [1, 15, 16, 11, 17, 18, 6, 19, 20, 21, 22, 2]   \n",
       "2  [1, 6, 23, 18, 6, 24, 25, 26, 19, 20, 16, 27, ...   \n",
       "4  [1, 15, 31, 32, 33, 18, 6, 21, 22, 26, 19, 20, 2]   \n",
       "\n",
       "                        A_indexes  \n",
       "1           [1, 4, 5, 6, 7, 8, 2]  \n",
       "2               [1, 9, 10, 11, 2]  \n",
       "4  [1, 4, 17, 6, 7, 9, 18, 19, 2]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_qa_trim.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7onEuVnwbEBq"
   },
   "outputs": [],
   "source": [
    "# functiojn to run the chatbot, give the input sentences and print the output\n",
    "\n",
    "def chatbot(sentence, model, vocabulary):\n",
    "    #sentence = train_data_qa_trim.iloc[n,1]\n",
    "    sentence = ''.join([s.lower() for s in sentence if s not in string.punctuation])\n",
    "    sentence = ' '.join(stemmer.stem(w) for w in sentence.split())\n",
    "    tokens = nltk.tokenize.RegexpTokenizer(r'\\w+').tokenize(sentence)\n",
    "\n",
    "    indices = [vocabulary.words2index[word] for word in tokens]\n",
    "    indices = [1] + indices + [2] \n",
    "    # indices\n",
    "    src = torch.Tensor(indices).long().to(device)\n",
    "    # print(src)\n",
    "    trg = torch.Tensor([0]*15).long().to(device)\n",
    "    # print(trg)\n",
    "    \n",
    "    teacher_force = 0\n",
    "    training = False\n",
    "    outcome = model(src, trg,teacher_force, training)\n",
    "    reply = []\n",
    "    for i in range(trg.size()[0]):\n",
    "      reply.append( TRG.index2word[int(torch.argmax(outcome[i],0).cpu().numpy())] )\n",
    "    # print(reply)\n",
    "    \n",
    "    # get clean reply without <SOS> and <EOS>\n",
    "    clean_reply = []\n",
    "    reply = reply[1:]\n",
    "    for i in reply:\n",
    "      if i != '<EOS>':\n",
    "        clean_reply.append(i)\n",
    "      if i == '<EOS>': break\n",
    "    clean_reply\n",
    "    if len(clean_reply) == 0:\n",
    "      clean_reply.append('THERE WERE NO PREDICTION')\n",
    "    clean_reply_str = (\" \".join(clean_reply))\n",
    "    # print(\"------------------------\")\n",
    "    print(\"Output: \", clean_reply_str, \"\\n\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QUw9GgZBV0fP",
    "outputId": "73d891f3-5d24-4917-fcaa-659b6a57d2a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your sentence \n",
      "\n",
      "Type 'exit' to exit from the chat.\n",
      " \n",
      "\n",
      "Input: How many student news papers are found at Notre Dame?\n",
      "Output:  three \n",
      "\n",
      "Input: What is the oldest structure at Notre Dame?\n",
      "Output:  old colleg \n",
      "\n",
      "Input: How many BS level degrees are offered in the College of Engineering at Notre Dame?\n",
      "Output:  eight \n",
      "\n",
      "Input: What is the daily student paper at Notre Dame called?\n",
      "Output:  the observ \n",
      "\n",
      "Input: The Basilica of the Sacred heart at Notre Dame is beside to which structure?\n",
      "Output:  the the great \n",
      "\n",
      "Input: exit\n"
     ]
    }
   ],
   "source": [
    "# Running the chatbot\n",
    "print(\"Enter your sentence\",'\\n')\n",
    "print(\"Type 'exit' to exit from the chat.\\n\", '\\n')\n",
    "\n",
    "while (True):\n",
    "    sentence = input(\"Input: \")\n",
    "    if sentence.strip() == \"exit\":\n",
    "        break\n",
    "    chatbot(sentence, seq2seq, SRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bPzF_qVQffhz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
